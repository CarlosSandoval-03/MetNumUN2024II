{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CarlosSandoval-03/MetNumUN2024II/blob/main/LAB%20ATQ/precheck.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JjM-EK8d6mtR"
      },
      "source": [
        "# Precheck\n",
        "\n",
        "With this template, you can find errors in your strategy before submitting.\n",
        "\n",
        "1) Click menu \"Kernel\" -> \"Restart Kernel and Run All Cells…\"\n",
        "\n",
        "2) Compare the strategy statistics with the results in strategy.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T-22fMyF6mtT",
        "outputId": "e7bef135-49b8-4f05-f9d8-02b444544a4a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Run init.ipynb..\n",
            "cmd:  jupyter nbconvert --to html --ExecutePreprocessor.timeout=1800 --execute init.ipynb --stdout | html2text -utf8\n",
            "output:\n",
            "[NbConvertApp] Converting notebook init.ipynb to html\n",
            "\n",
            "\n",
            "\n",
            "****** Dependencies¶ ******\n",
            "Use this file to add external dependencies. The evaluator will run this file\n",
            "once to prepare the environment for your strategy.\n",
            "Jupyter allows you to run shell commands using !.\n",
            "In [1]:\n",
            "! conda info\n",
            "Error while loading conda entry point: conda-libmamba-solver (libarchive.so.20:\n",
            "cannot open shared object file: No such file or directory)\n",
            "/usr/local/lib/python3.10/site-packages/conda/base/context.py:982:\n",
            "FutureWarning: Adding 'defaults' to the channel list implicitly is deprecated\n",
            "and will be removed in 25.3.\n",
            "\n",
            "To remove this warning, please choose a default channel explicitly via 'conda\n",
            "config --add channels <name>', e.g. 'conda config --add channels defaults'.\n",
            "  deprecated.topic(\n",
            "\n",
            "     active environment : base\n",
            "    active env location : /usr/local\n",
            "            shell level : 1\n",
            "       user config file : /root/.condarc\n",
            " populated config files :\n",
            "          conda version : 24.9.1\n",
            "    conda-build version : not installed\n",
            "         python version : 3.10.13.final.0\n",
            "                 solver : libmamba (default)\n",
            "       virtual packages : __archspec=1=haswell\n",
            "                          __conda=24.9.1=0\n",
            "                          __glibc=2.31=0\n",
            "                          __linux=4.18.0=0\n",
            "                          __unix=0=0\n",
            "       base environment : /usr/local  (writable)\n",
            "      conda av data dir : /usr/local/etc/conda\n",
            "  conda av metadata url : None\n",
            "           channel URLs : https://repo.anaconda.com/pkgs/main/linux-64\n",
            "                          https://repo.anaconda.com/pkgs/main/noarch\n",
            "                          https://repo.anaconda.com/pkgs/r/linux-64\n",
            "                          https://repo.anaconda.com/pkgs/r/noarch\n",
            "          package cache : /usr/local/pkgs\n",
            "                          /root/.conda/pkgs\n",
            "       envs directories : /usr/local/envs\n",
            "                          /root/.conda/envs\n",
            "               platform : linux-64\n",
            "             user-agent : conda/24.9.1 requests/2.32.3 CPython/3.10.13 Linux/\n",
            "4.18.0-553.30.1.el8_10.x86_64 ubuntu/20.04.6 glibc/2.31 solver/libmamba aau/\n",
            "0.4.4 c/. s/. e/.\n",
            "                UID:GID : 0:0\n",
            "             netrc file : None\n",
            "           offline mode : False\n",
            "\n",
            "You can use it to install external dependencies. We suggest use conda for this:\n",
            "In [2]:\n",
            "# ! conda install -y scikit-learn\n",
            "But you can use pip or other tools if you need them.\n",
            "In [3]:\n",
            "# ! pip install sklearn2\n",
            "return code: 0\n",
            "Output directory is: precheck_results\n",
            "Rm previous results...\n",
            "Prepare test dates...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100% (44115 of 44115) |##################| Elapsed Time: 0:00:00 Time:  0:00:00\n",
            "100% (13194104 of 13194104) |############| Elapsed Time: 0:00:00 Time:  0:00:00\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fetched chunk 1/7 1s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100% (13194104 of 13194104) |############| Elapsed Time: 0:00:00 Time:  0:00:00\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fetched chunk 2/7 1s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100% (13194104 of 13194104) |############| Elapsed Time: 0:00:00 Time:  0:00:00\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fetched chunk 3/7 2s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100% (13194072 of 13194072) |############| Elapsed Time: 0:00:00 Time:  0:00:00\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fetched chunk 4/7 3s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100% (13193988 of 13193988) |############| Elapsed Time: 0:00:00 Time:  0:00:00\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fetched chunk 5/7 4s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100% (13193988 of 13193988) |############| Elapsed Time: 0:00:00 Time:  0:00:00\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fetched chunk 6/7 5s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100% (6760092 of 6760092) |##############| Elapsed Time: 0:00:00 Time:  0:00:00\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fetched chunk 7/7 5s\n",
            "Data loaded 5s\n",
            "Dates: 2006-01-04 2015-07-09 2025-01-10\n",
            "---\n",
            "pass: 1 / 3 max_date: 2006-01-04\n",
            "cmd: DATA_BASE_URL=http://hl.datarelay:7070/last/2006-01-04/ \\\n",
            "LAST_DATA_PATH=../last_data.txt \\\n",
            "OUTPUT_PATH=../fractions.nc.gz \\\n",
            "SUBMISSION_ID=-1\\\n",
            " jupyter nbconvert --to html --ExecutePreprocessor.timeout=1800 --execute strategy.ipynb --output=../strategy.html\n",
            "output:\n",
            "[NbConvertApp] Converting notebook strategy.ipynb to html\n",
            "[NbConvertApp] Writing 375367 bytes to ../strategy.html\n",
            "return code: 0\n",
            "Check the output...\n",
            "Load data...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100% (18344 of 18344) |##################| Elapsed Time: 0:00:00 Time:  0:00:00\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fetched chunk 1/1 1s\n",
            "Data loaded 1s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR! The output contains illiquid positions.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "There are no missed dates.\n",
            "---\n",
            "pass: 2 / 3 max_date: 2015-07-09\n",
            "cmd: DATA_BASE_URL=http://hl.datarelay:7070/last/2015-07-09/ \\\n",
            "LAST_DATA_PATH=../last_data.txt \\\n",
            "OUTPUT_PATH=../fractions.nc.gz \\\n",
            "SUBMISSION_ID=-1\\\n",
            " jupyter nbconvert --to html --ExecutePreprocessor.timeout=1800 --execute strategy.ipynb --output=../strategy.html\n",
            "output:\n",
            "[NbConvertApp] Converting notebook strategy.ipynb to html\n",
            "[NbConvertApp] Writing 479565 bytes to ../strategy.html\n",
            "return code: 0\n",
            "Check the output...\n",
            "Load data...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100% (3842476 of 3842476) |##############| Elapsed Time: 0:00:00 Time:  0:00:00\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fetched chunk 1/6 0s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100% (4608944 of 4608944) |##############| Elapsed Time: 0:00:00 Time:  0:00:00\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fetched chunk 2/6 1s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100% (1543084 of 1543084) |##############| Elapsed Time: 0:00:00 Time:  0:00:00\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fetched chunk 3/6 1s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100% (163184 of 163184) |################| Elapsed Time: 0:00:00 Time:  0:00:00\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fetched chunk 4/6 1s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100% (623324 of 623324) |################| Elapsed Time: 0:00:00 Time:  0:00:00\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fetched chunk 5/6 1s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100% (8594516 of 8594516) |##############| Elapsed Time: 0:00:00 Time:  0:00:00\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fetched chunk 6/6 2s\n",
            "Data loaded 2s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR! The output contains illiquid positions.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "There are no missed dates.\n",
            "---\n",
            "pass: 3 / 3 max_date: 2025-01-10\n",
            "cmd: DATA_BASE_URL=http://hl.datarelay:7070/last/2025-01-10/ \\\n",
            "LAST_DATA_PATH=../last_data.txt \\\n",
            "OUTPUT_PATH=../fractions.nc.gz \\\n",
            "SUBMISSION_ID=-1\\\n",
            " jupyter nbconvert --to html --ExecutePreprocessor.timeout=1800 --execute strategy.ipynb --output=../strategy.html\n",
            "output:\n",
            "[NbConvertApp] Converting notebook strategy.ipynb to html\n"
          ]
        }
      ],
      "source": [
        "from qnt.precheck import *\n",
        "\n",
        "data_type = 'stocks_nasdaq100'  # 'futures', 'stocks', 'futures', 'cryptofutures'\n",
        "\n",
        "run_init()\n",
        "# Runs your strategy multiple times cutting the data tail.\n",
        "# It is similar to the step-by-step calculation.\n",
        "evaluate_passes(passes=3, data_type=data_type)\n",
        "weights = assemble_output()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BidDuU6a6mtV"
      },
      "outputs": [],
      "source": [
        "# run this code for your strategy in strategy.ipnb and compare the results\n",
        "import qnt.data as qndata\n",
        "import qnt.stats as qns\n",
        "import qnt.graph as qngraph\n",
        "\n",
        "data = qndata.stocks.load_ndx_data(min_date=\"2006-01-01\")\n",
        "stats = qns.calc_stat(data, weights.sel(time=slice(\"2006-01-01\", None)))\n",
        "display(stats.to_pandas().tail())\n",
        "\n",
        "performance = stats.to_pandas()[\"equity\"]\n",
        "qngraph.make_plot_filled(performance.index, performance, name=\"PnL (Equity)\", type=\"log\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w96o_yNi6mtW"
      },
      "source": [
        "# Common mistakes\n",
        "\n",
        "Aggregate functions can bring knowledge from the future to the past. You can subtract the average or maximum value from each point in the time series. The maximum value may be in 2021, but how is this known from 2015?\n",
        "\n",
        "```python\n",
        "close = data.sel(field=\"close\")\n",
        "\n",
        "weights = close - close.max()\n",
        "weights = close - close.min()\n",
        "weights = close - close.std()\n",
        "weights = close - close.sum()\n",
        "```\n",
        "\n",
        "Use future knowledge in the past\n",
        "\n",
        "```python\n",
        "weights = close.shift(time=-1)\n",
        "```\n",
        "\n",
        "Advance/Decline Line and Advance/Decline Ratio\n",
        "\n",
        "```python\n",
        "# no correct\n",
        "close = data.sel(field=\"close\")\n",
        "weights = qnta.ad_line(close) * 1.0\n",
        "weights = qnta.ad_ratio(close) * 1.0\n",
        "\n",
        "# correct code\n",
        "close = data.sel(field=\"close\") * data.sel(field=\"is_liquid\")\n",
        "weights = qnta.ad_line(close) * 1.0\n",
        "weights = qnta.ad_ratio(close) * 1.0\n",
        "\n",
        "```\n",
        "\n",
        "Standardization in price processing brings knowledge from the future to the past.\n",
        "\n",
        "```python\n",
        "def get_preprocessing(prices):\n",
        "   from sklearn.preprocessing import StandardScaler\n",
        "   scaler = StandardScaler()\n",
        "\n",
        "   prices_pandas = prices.to_pandas()\n",
        "   assets = data.coords[\"asset\"].values\n",
        "   for asset in assets:\n",
        "       prices_pandas[asset] = scaler.fit_transform(prices_pandas[asset].values.reshape(-1, 1))\n",
        "   return prices_pandas\n",
        "\n",
        "prices = data.sel(field=\"close\").fillna(0) * 1.0  # fill NaN\n",
        "prices_standard_scaler = get_preprocessing(prices)\n",
        "```\n",
        "\n",
        "Quantile\n",
        "\n",
        "```python\n",
        "weights = (close < close.quantile(0.30, dim='asset'))*1\n",
        "```\n",
        "\n",
        "# How this template works\n",
        "\n",
        "Runs your strategy multiple times cutting the data tail. It is similar to the step-by-step calculation.\n",
        "\n",
        "By default, it runs 3 passes. It is enough to catch most errors. If you want to get more relevant results, you need to increase the number of passes. When you submit your strategy, the system runs about 1000 passes, which requires a very long time.\n",
        "\n",
        "Also, this step performs some intermediate checks of the outputs.\n",
        "\n",
        "When passes finish, you can find results in the folder `precheck_results`.\n",
        "\n",
        "```python\n",
        "\n",
        "evaluate_passes(passes=3, data_type=data_type)\n",
        "\n",
        "# you can also set the the specific dates:\n",
        "# evaluate_passes(dates=['2016-09-30', '2018-07-13', '2020-04-23'])\n",
        "```\n",
        "\n",
        "Assembles the output from the outputs calculated in the previous step.\n",
        "\n",
        "```python\n",
        "weights = assemble_output()\n",
        "```\n",
        "\n",
        "You can use a function to check the result\n",
        "\n",
        "```python\n",
        "check_output(weights, data_type=data_type)\n",
        "```\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "@webio": {
      "lastCommId": null,
      "lastKernelId": null
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}